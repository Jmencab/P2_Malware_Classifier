from pprint import pprint
from collections import Counter
import os
import util
import pandas as pd
import csv
import numpy as np
import xgboost as xgb
from sklearn.naive_bayes import BernoulliNB as bnb
try:
    import xml.etree.cElementTree as ET
except ImportError:
    import xml.etree.ElementTree as ET

SPLIT = .80

data = np.genfromtxt('trainsys.csv', delimiter=',')
sz = data.shape

train = data[1:int(sz[0] * SPLIT), 1:]
test = data[int(sz[0] * SPLIT):, 1:]

train_X = train[:, 1:]
train_Y = train[:, 0]

test_X = test[:, 1:]
test_Y = test[:, 0]

xg_train = xgb.DMatrix(train_X, label=train_Y)
xg_test = xgb.DMatrix(test_X, label=test_Y)

# setup parameters for softmax classification
param = {}
param['objective'] = 'multi:softmax'
param['eta'] = 0.2
param['max_depth'] = 9
param['silent'] = 1
param['num_class'] = 15
num_round = 30

watchlist = [(xg_train, 'train'), (xg_test, 'test')]
bst = xgb.train(param, xg_train, num_round, watchlist)

# get predictions
pred = bst.predict(xg_test)
error_rate = np.sum(pred != test_Y) / float( test_Y.shape[0])
print('Test error using softmax = {}'.format(error_rate))

# datar = np.genfromtxt('test.csv', delimiter=',')
# testr = datar[:, 1:]
# testr_X = testr[:, 1:]
# testr_Y = testr[:, 0]
# xg_testr = xgb.DMatrix(testr_X, label=testr_Y)

# predr = bst.predict(xg_testr)

# ids = []
# with open("test.csv") as f:
#     reader = csv.reader(f, delimiter=",")
#     for i in reader:
#         ids.append(i[0])

#util.write_predictions(predr, ids, "0.csv")
