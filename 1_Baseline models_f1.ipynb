{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS181_P2 Baseline models trained on feature No.1 (Choppy)\n",
    "\n",
    "**No model tunning for the Choppy features, sorry...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I Data Preprocessing\n",
    "### 1. Read in raw data\n",
    "- choppyTrain.csv -> df_train_0\n",
    "- choppyTest.csv -> df_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "#            Data Preprocessing               #\n",
    "###############################################\n",
    "\n",
    "## 1. Read in raw data\n",
    "# use panda to read in data\n",
    "df_train_0 = pd.read_csv(\"choppyTrain.csv\")\n",
    "df_test_0 = pd.read_csv(\"choppyTest.csv\")\n",
    "# view the train data\n",
    "#df_train_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2. Clean data\n",
    "# 2.1 combine train and test for easier feature engineering\n",
    "# (1) delete 'Id' column\n",
    "df_test = df_test_0.drop(['Id'], axis=1)\n",
    "df_train = df_train_0.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. specify x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (3086, 20)\n",
      "Train Class: (3086,)\n",
      "Test features: (3724, 20)\n"
     ]
    }
   ],
   "source": [
    "# Specify x and y\n",
    "# 3.1 specify Class values as y\n",
    "Y_train = df_train.Class.values\n",
    "\n",
    "# 3.2 specify x values\n",
    "X_train = df_train.drop(['Class'], axis=1).values\n",
    "X_test = df_test.drop(['Class'], axis=1).values\n",
    "\n",
    "# 3.3 view data structure\n",
    "print(\"Train features:\", X_train.shape)\n",
    "print(\"Train Class:\", Y_train.shape)\n",
    "print(\"Test features:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the feature space for model tunning\n",
    "#np.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
    "#np.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
    "#np.savetxt(\"Y_train.csv\", Y_train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. split the training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II Baseline models\n",
    "\n",
    "### 1. Logistic Regression Classifier\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "- **multi_class** : \n",
    "    - **‘ovr’**: softmax(one over all)\n",
    "    - **‘multinomial’**: one over another(the reference group)\n",
    "- **class_weight** : \n",
    "    - **‘balanced’**: uses the values of y to automatically **adjust weights inversely proportional to class frequencies** in the input data as **n_samples / (n_classes * np.bincount(y))**, these weights will be **multiplied with sample_weight** (passed through the fit method) if sample_weight is specified.\n",
    "    - **unbalanced(by default)**: not adjust weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "#              Baseline Methods               #\n",
    "###############################################\n",
    "# 1. Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Weighted Logistic Regression Classifier - one_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.1 Weighted Logistic Regression Classifier - one_vs_rest\n",
    "# fit the model\n",
    "wlogi_ovr = LogisticRegressionCV(class_weight='balanced', multi_class= 'ovr')\n",
    "wlogi_ovr.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "wlogi_ovr_train = wlogi_ovr.predict(x_train)\n",
    "wlogi_ovr_test = wlogi_ovr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.627228525122\n",
      "accuracy for test set is:  0.587378640777\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, wlogi_ovr_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, wlogi_ovr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Weighted Logistic Regression Classifier - multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.2 Weighted Logistic Regression Classifier -multinomial\n",
    "# fit the model\n",
    "wlogi_multi = LogisticRegressionCV(class_weight='balanced', multi_class= 'multinomial')\n",
    "wlogi_multi.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "wlogi_multi_train = wlogi_multi.predict(x_train)\n",
    "wlogi_multi_test = wlogi_multi.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.410858995138\n",
      "accuracy for test set is:  0.391585760518\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, wlogi_multi_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, wlogi_multi_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Uneighted Logistic Regression Classifier - one_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.3 Unweighted Logistic Regression Classifier - one_vs_rest\n",
    "# fit the model\n",
    "logi_ovr = LogisticRegressionCV(multi_class= 'ovr')\n",
    "logi_ovr.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "logi_ovr_train = logi_ovr.predict(x_train)\n",
    "logi_ovr_test = logi_ovr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.720826580227\n",
      "accuracy for test set is:  0.68284789644\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, logi_ovr_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, logi_ovr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Unweighted Logistic Regression Classifier - multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.4 Unweighted Logistic Regression Classifier -multinomial\n",
    "# fit the model\n",
    "logi_multi = LogisticRegressionCV(multi_class= 'multinomial')\n",
    "logi_multi.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "logi_multi_train = logi_multi.predict(x_train)\n",
    "logi_multi_test = logi_multi.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.720826580227\n",
      "accuracy for test set is:  0.68284789644\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, logi_multi_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, logi_multi_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaussian Process Classifier (not applied due to computation complexity )\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html\n",
    "\n",
    "- **multi_class** : \n",
    "    - **“one_vs_rest”**: one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. \n",
    "    - **“one_vs_one”**: one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Gaussian Process Classifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Gaussian Process Classifier - one_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.1 Gaussian Process Classifier - one_vs_rest\n",
    "# fit the model\n",
    "GPC_ovr = GaussianProcessClassifier(multi_class= 'one_vs_rest')\n",
    "GPC_ovr.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "GPC_ovr_train = GPC_ovr.predict(x_train)\n",
    "GPC_ovr_test = GPC_ovr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, GPC_ovr_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, GPC_ovr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Gaussian Process Classifier - one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.2 Gaussian Process Classifier - one_vs_one\n",
    "# fit the model\n",
    "GPC_multi = GaussianProcessClassifier(multi_class= 'one_vs_one')\n",
    "GPC_multi.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "GPC_multi_train = GPC_multi.predict(x_train)\n",
    "GPC_multi_test = GPC_multi.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, GPC_multi_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, GPC_multi_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tree-based\n",
    "**Difference** between **Extra Tree** and **Random Forest** is *how they choose feature as split node* once they've randomly generated subset of parameters for splitting: **Random Forest** will choose the **most distinguishable feature** as the split node(which makes each single trees more similar to each other, since they all tend to choose the most distinguishable one as the first split node), while **Extra Tree** would pick the split nodes **totally at random**. This means, by taking the avarage of all single trees, **Extra Tree can reduce more variance**. \n",
    "#### 3.1 Extra Tree Classifier\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Tree-based classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.1 Extra Trees Classifier\n",
    "# fit the model\n",
    "ET = ExtraTreesClassifier(n_estimators=30)\n",
    "ET.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "ET_train = ET.predict(x_train)\n",
    "ET_test = ET.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.915721231767\n",
      "accuracy for test set is:  0.733009708738\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, ET_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, ET_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random Forest Classifier\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.2 Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "RF = RandomForestClassifier(n_estimators=30)\n",
    "RF.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "RF_train = RF.predict(x_train)\n",
    "RF_test = RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.920583468395\n",
      "accuracy for test set is:  0.736245954693\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, RF_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, RF_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "#### (1) unweighted svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. SVM\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.1 unweighted \n",
    "# fit the model\n",
    "svm = svm.SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "svm_train = svm.predict(x_train)\n",
    "svm_test = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.724878444084\n",
      "accuracy for test set is:  0.690938511327\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, svm_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) weighted svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.2 weighted svm\n",
    "# fit the model\n",
    "wsvm = svm.SVC(class_weight='balanced')\n",
    "wsvm.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "wsvm_train = wsvm.predict(x_train)\n",
    "wsvm_test = wsvm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.518638573744\n",
      "accuracy for test set is:  0.495145631068\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, wsvm_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, wsvm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. BNB\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. BNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "BNB_train = BNB.predict(x_train)\n",
    "BNB_test = BNB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.703808752026\n",
      "accuracy for test set is:  0.681229773463\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, BNB_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, BNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Neural Network\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "NN = MLPClassifier()\n",
    "NN.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "NN_train = NN.predict(x_train)\n",
    "NN_test = NN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.829011345219\n",
      "accuracy for test set is:  0.736245954693\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, NN_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, NN_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Knn\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "knn_train = knn.predict(x_train)\n",
    "knn_test = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.798217179903\n",
      "accuracy for test set is:  0.699029126214\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training set is: \", accuracy_score(y_train, knn_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "for ID in df_test_0['Id'].values:\n",
    "    test_ids.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for\n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction from RF: 0.58623\n",
    "RF_Test = RF.predict(X_test)\n",
    "write_predictions(RF_Test,test_ids,\"ChoppyRF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction from NN: 0.62947\n",
    "NN_Test = NN.predict(X_test)\n",
    "write_predictions(NN_Test,test_ids,\"ChoppyNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction from logi_ovr: 0.57824\n",
    "logi_ovr_Test = logi_ovr.predict(X_test)\n",
    "write_predictions(logi_ovr_Test,test_ids,\"Choppylogi_ovr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction from knn: 0.56263\n",
    "knn_Test = knn.predict(X_test)\n",
    "write_predictions(knn_Test,test_ids,\"Choppyknn.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
