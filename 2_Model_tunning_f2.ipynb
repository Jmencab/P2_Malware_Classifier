{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS181_P2 Model_tunning for feature No.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I  load in the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in variable space\n",
    "X_train = np.loadtxt(\"X_train.csv\",delimiter=\",\")\n",
    "X_test = np.loadtxt(\"X_test.csv\",delimiter=\",\")\n",
    "Y_train = np.loadtxt(\"Y_train.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 107)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II Models Tunning\n",
    "### 1. ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best max_depth is:  60\n",
      "The best n_estimators is:  70\n"
     ]
    }
   ],
   "source": [
    "# tunning the model use 5-cv\n",
    "parameters = {\"max_depth\": [10,20,50,60,80,100]\n",
    "                        #,\"min_samples_split\" :[2,10,50,500,1000]\n",
    "                        ,\"n_estimators\" : [30,50,70]}\n",
    "                        #,\"min_samples_leaf\": [2,10,50,500,1000]\n",
    "                        #,\"max_features\": ('auto','sqrt','log2')\n",
    "ET_regr = ExtraTreesClassifier()\n",
    "model = GridSearchCV(ET_regr,parameters, cv = 10)\n",
    "fit = model.fit(x_train,y_train)\n",
    "learned_parameters = fit.best_params_ \n",
    "# Rerun model on fitted parameters \n",
    "ET = ExtraTreesClassifier(max_depth = learned_parameters[\"max_depth\"])\n",
    "                            #,max_features = 'sqrt'\n",
    "                            #,min_samples_leaf = learned_parameters['min_samples_leaf']\n",
    "                            #,min_samples_split = learned_parameters['min_samples_split']\n",
    "                            #,n_estimators = learned_parameters['n_estimators']\n",
    "ET_fit = ET.fit(x_train,y_train)\n",
    "print(\"The best max_depth is: \", learned_parameters[\"max_depth\"])\n",
    "print(\"The best n_estimators is: \", learned_parameters[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.991085899514\n",
      "accuracy for test set is:  0.886731391586\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test\n",
    "ET_train = ET_fit.predict(x_train)\n",
    "ET_test = ET_fit.predict(x_test)\n",
    "print(\"accuracy for training set is: \", accuracy_score(y_train, ET_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, ET_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like ExtraTrees can't be improved further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Neural Network\n",
    "- **learning_rate_init**: The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=’sgd’ or ‘adam’\n",
    "- **alpha**: L2 penalty (regularization term) parameter.\n",
    "- **activation**: Activation function for the hidden layer.\n",
    "    - **identity**: no-op activation, useful to implement linear bottleneck, returns **f(x) = x**\n",
    "    - **logistic**: the logistic sigmoid function, returns **f(x) = 1 / (1 + exp(-x))**.\n",
    "    - **tanh**: the hyperbolic tan function, returns **f(x) = tanh(x)**.\n",
    "    - **relu**: the rectified linear unit function, returns **f(x) = max(0, x)**\n",
    "- **hidden_layer_sizes**: The ith element represents the number of neurons in the ith hidden layer. length = n_layers - 2, default (100,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cut down the computation time, I tunned those parameters one by one:\n",
    "#### 1. activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/xihanzhang/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best activation is:  logistic\n"
     ]
    }
   ],
   "source": [
    "# tunning the model use 5-cv\n",
    "parameters = {#\"learning_rate_init\": [0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
    "                        #,\"hidden_layer_sizes\" :[(10,),(50,),(100,),(200,)]\n",
    "                        #,\"alpha\" : [1,0.01,0.0001]\n",
    "                        \"activation\": ('identity', 'logistic', 'tanh', 'relu')}\n",
    "NN_regr = MLPClassifier()\n",
    "model = GridSearchCV(NN_regr,parameters, cv = 5)\n",
    "fit = model.fit(x_train,y_train)\n",
    "learned_parameters = fit.best_params_ \n",
    "\n",
    "# Rerun model on fitted parameters \n",
    "NN = MLPClassifier(#learning_rate_init = learned_parameters[\"learning_rate_init\"])\n",
    "                            #,hidden_layer_sizes = learned_parameters[\"hidden_layer_sizes\"]\n",
    "                            #,alpha = learned_parameters['alpha']\n",
    "                            activation = learned_parameters['activation'])\n",
    "NN_fit = NN.fit(x_train,y_train)\n",
    "#print(\"The best learning_rate is: \", learned_parameters[\"learning_rate_init\"])\n",
    "#print(\"The best hidden_layer_sizes is: \", learned_parameters[\"hidden_layer_sizes\"])\n",
    "print(\"The best activation is: \", learned_parameters[\"activation\"])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.940437601297\n",
      "accuracy for test set is:  0.86569579288\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test\n",
    "NN_train = NN_fit.predict(x_train)\n",
    "NN_test = NN_fit.predict(x_test)\n",
    "print(\"accuracy for training set is: \", accuracy_score(y_train, NN_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, NN_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've tried several times and get the result: **\"logistic\"** is the best **activation**.\n",
    "#### 2. hidden_layer_sizes & learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best learning_rate is:  0.01\n",
      "The best hidden_layer_sizes is:  (400, 300)\n"
     ]
    }
   ],
   "source": [
    "# tunning the model use 5-cv\n",
    "parameters = {\"learning_rate_init\": [0.01, 0.001, 0.0001]\n",
    "                        ,\"hidden_layer_sizes\" :[(400,200),(400,300),(400,400)]}\n",
    "                        #,\"alpha\" : [1,0.01,0.0001]\n",
    "                        #,\"activation\": ('identity', 'logistic', 'tanh', 'relu')\n",
    "NN_regr = MLPClassifier()\n",
    "model = GridSearchCV(NN_regr,parameters, cv = 5)\n",
    "fit = model.fit(x_train,y_train)\n",
    "learned_parameters = fit.best_params_ \n",
    "\n",
    "# Rerun model on fitted parameters \n",
    "NN_2 = MLPClassifier(learning_rate_init = learned_parameters[\"learning_rate_init\"]\n",
    "                            ,hidden_layer_sizes = learned_parameters[\"hidden_layer_sizes\"]\n",
    "                            #,alpha = learned_parameters['alpha']\n",
    "                            ,activation = 'logistic')\n",
    "NN_2_fit = NN_2.fit(x_train,y_train)\n",
    "print(\"The best learning_rate is: \", learned_parameters[\"learning_rate_init\"])\n",
    "print(\"The best hidden_layer_sizes is: \", learned_parameters[\"hidden_layer_sizes\"])\n",
    "#print(\"The best activation is: \", learned_parameters[\"activation\"])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.926661264182\n",
      "accuracy for test set is:  0.867313915858\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test\n",
    "NN_2_train = NN_2_fit.predict(x_train)\n",
    "NN_2_test = NN_2_fit.predict(x_test)\n",
    "print(\"accuracy for training set is: \", accuracy_score(y_train, NN_2_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, NN_2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1)\n",
    "    - \"learning_rate_init\": [0.001, 0.00001, 0.0000001]\n",
    "    - \"hidden_layer_sizes\" :[(50,),(100,),(200,)]\n",
    "    - The best learning_rate is:  0.001\n",
    "    - The best hidden_layer_sizes is:  (200,)\n",
    "    - accuracy for training set is:  0.955834683955\n",
    "    - accuracy for test set is:  0.873786407767\n",
    "- (2)\n",
    "    - \"learning_rate_init\": [0.1, 0.01, 0.001]\n",
    "    - \"hidden_layer_sizes\" :[(200,),(300,),(400,)]\n",
    "    - The best learning_rate is:  0.01\n",
    "    - The best hidden_layer_sizes is:  (400,)\n",
    "    - accuracy for training set is:  0.931928687196\n",
    "    - accuracy for test set is:  0.875404530744\n",
    "- (3)\n",
    "    - \"hidden_layer_sizes\" :[(400,2),(400,5),(400,10),(400,50)]\n",
    "    - learning_rate_init = 0.01\n",
    "    - The best hidden_layer_sizes is:  (400, 50)\n",
    "    - accuracy for training set is:  0.918962722853\n",
    "    - accuracy for test set is:  0.857605177994\n",
    "- (4)\n",
    "    - \"learning_rate_init\": [0.01, 0.001, 0.0001]\n",
    "    - \"hidden_layer_sizes\" :[(400,200), (400,300), (400,400)]\n",
    "    - The best learning_rate is:  0.01\n",
    "    - The best hidden_layer_sizes is:  (400, 300)\n",
    "    - accuracy for training set is:  0.926661264182\n",
    "    - accuracy for test set is:  0.867313915858\n",
    "\n",
    "**Thus, I would use the parameters from(4)**:\n",
    "- learning_rate_init = 0.01\n",
    "- hidden_layer_sizes = (400, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is:  1e-05\n"
     ]
    }
   ],
   "source": [
    "# tunning the model use 5-cv\n",
    "parameters = {#\"learning_rate_init\": [0.01, 0.001, 0.0001]\n",
    "                        #,\"hidden_layer_sizes\" :[(400,50),(400,100),(400,200)]\n",
    "                        \"alpha\" : [0.001, 0.0001, 0.00001, 0.000001]}\n",
    "                        #,\"activation\": ('identity', 'logistic', 'tanh', 'relu')\n",
    "NN_regr = MLPClassifier()\n",
    "model = GridSearchCV(NN_regr,parameters, cv = 5)\n",
    "fit = model.fit(x_train,y_train)\n",
    "learned_parameters = fit.best_params_ \n",
    "\n",
    "# Rerun model on fitted parameters \n",
    "NN_3 = MLPClassifier(learning_rate_init = 0.01\n",
    "                            ,hidden_layer_sizes = (400, 300)\n",
    "                            ,alpha = learned_parameters['alpha']\n",
    "                            ,activation = 'logistic')\n",
    "NN_3_fit = NN_3.fit(x_train,y_train)\n",
    "#print(\"The best learning_rate is: \", learned_parameters[\"learning_rate_init\"])\n",
    "#print(\"The best hidden_layer_sizes is: \", learned_parameters[\"hidden_layer_sizes\"])\n",
    "#print(\"The best activation is: \", learned_parameters[\"activation\"])  \n",
    "print(\"The best alpha is: \", learned_parameters[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.927876823339\n",
      "accuracy for test set is:  0.873786407767\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test\n",
    "NN_3_train = NN_3_fit.predict(x_train)\n",
    "NN_3_test = NN_3_fit.predict(x_test)\n",
    "print(\"accuracy for training set is: \", accuracy_score(y_train, NN_3_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, NN_3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1)\n",
    "    - \"alpha\" : [1,0.01,0.0001]\n",
    "    - The best alpha is:  0.0001\n",
    "    - accuracy for training set is:  0.948136142626\n",
    "    - accuracy for test set is:  0.875404530744\n",
    "    \n",
    "- (2)\n",
    "    - \"alpha\" : [0.001, 0.0001, 0.00001, 0.000001]\n",
    "    - The best alpha is:  0.00001\n",
    "    - accuracy for training set is:  0.927876823339\n",
    "    - accuracy for test set is:  0.873786407767\n",
    "Then, the final parameters are:\n",
    "- learning_rate_init = 0.01\n",
    "- hidden_layer_sizes = (400, 300)\n",
    "- alpha = 0.00001\n",
    "- activation = 'logistic'\n",
    "### the final NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = MLPClassifier(learning_rate_init = 0.01, \n",
    "                   hidden_layer_sizes = (400, 300), \n",
    "                   alpha = 0.00001, \n",
    "                   activation = 'logistic')\n",
    "NN.fit(x_train, y_train)\n",
    "# predict on train and test\n",
    "NN_train = NN.predict(x_train)\n",
    "NN_test = NN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set is:  0.940437601297\n",
      "accuracy for test set is:  0.86569579288\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test\n",
    "NN_train = NN_fit.predict(x_train)\n",
    "NN_test = NN_fit.predict(x_test)\n",
    "print(\"accuracy for training set is: \", accuracy_score(y_train, NN_train))\n",
    "print(\"accuracy for test set is: \", accuracy_score(y_test, NN_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably **Neuro Net can't be improved too much**, and not as promissing as ExtraTrees.\n",
    "Then, I would switch to **Oxgboost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_0 = pd.read_csv(\"perSysCountsTrain.csv\")\n",
    "df_test_0 = pd.read_csv(\"perSysCountsTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "for ID in df_test_0['Id'].values:\n",
    "    test_ids.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for\n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction from NN_final: 0.75737\n",
    "NN_final_Test = NN.predict(X_test)\n",
    "write_predictions(NN_final_Test,test_ids,\"NN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
